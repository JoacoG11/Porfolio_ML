<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="tipos_algoritmos.css">
    <title>Tipos de Algoritmos</title>
</head>
<body>
    <header>
        <h1>Tipos de Algoritmos</h1>
    </header>
    <main>

        <p>Los algoritmos de Machine Learning son el núcleo de esta disciplina y se utilizan para resolver una amplia variedad de problemas. Comprender estos algoritmos es esencial para aplicar Machine Learning de manera efectiva. Aquí exploramos algunos de los tipos más comunes:</p>
        
        <section>
            <h2>Regresión Lineal:</h2>
            <p>
                <li><strong>Nombre:</strong> Regresión Lineal.<br></li>
                <li><strong>Especificaciones:</strong> La regresión lineal es un método estadístico utilizado en problemas de regresión para modelar la relación entre una variable dependiente (objetivo) y una o más variables independientes (características) mediante una ecuación lineal.<br></li>
                <li><strong>Características:</strong> Es un enfoque simple pero poderoso para entender y predecir relaciones lineales entre variables. Puede ser un punto de partida efectivo para el análisis de datos y la predicción numérica.<br></li>
                <li><strong>Fortalezas:</strong> Su simplicidad lo hace fácil de entender y de implementar. Proporciona coeficientes que indican la importancia de cada característica en la predicción.<br></li>
                <li><strong>Fundamentos:</strong> La regresión lineal se basa en el principio de encontrar la mejor línea recta que minimice el error cuadrático medio entre las predicciones y los valores reales.
            </p>
        </section>

        <section>
            <h2>Árboles de Decisión:</h2>
            <p>
                <li><strong>Nombre:</strong> Árboles de Decisión.<br>
                <li><strong>Especificaciones:</strong> Los árboles de decisión son modelos que se utilizan tanto en problemas de clasificación como en regresión. Dividen un conjunto de datos en subconjuntos más pequeños en función de características, utilizando una estructura de árbol.<br></li>
                <li><strong>Características:</strong> Son altamente interpretables, lo que significa que se pueden visualizar fácilmente. Pueden manejar datos categóricos y numéricos.<br></li>
                <li><strong>Fortalezas:</strong> Los árboles de decisión son resistentes al ruido y pueden capturar relaciones no lineales en los datos. Son útiles para la toma de decisiones basadas en reglas claras y simples.<br></li>
                <li><strong>Fundamentos:</strong> Utilizan criterios como la ganancia de información o la impureza de Gini para decidir cómo dividir los datos en cada nodo del árbol.</li>
            </p>
        </section>

        <section>
            <h2>Máquinas de Vectores de Soporte (SVM):</h2>
            <p>
                <li><strong>Nombre:</strong> Máquinas de Vectores de Soporte (SVM).<br>
                <li><strong>Especificaciones:</strong> Las SVM se utilizan tanto en problemas de clasificación como en regresión. Buscan encontrar un hiperplano en un espacio de alta dimensión que mejor separe las clases.<br></li>
                <li><strong>Características:</strong> Son efectivas en espacios de alta dimensión y pueden manejar datos no lineales utilizando kernels. Pueden adaptarse a problemas de clasificación binaria y múltiple.<br></li>
                <li><strong>Fortalezas:</strong> Son robustas en la clasificación de datos no lineales y tienen una sólida fundamentación matemática. Pueden manejar conjuntos de datos de gran tamaño.<br></li>
                <li><strong>Fundamentos:</strong> Las SVM se basan en la idea de maximizar el margen entre las clases al encontrar el hiperplano óptimo.</li>
            </p>
        </section>

        <section>
            <h2>K-Nearest Neighbors (K-NN):</h2>
            <p>
                <li><strong>Nombre:</strong> K-Nearest Neighbors (K-NN).<br>
                <li><strong>Especificaciones:</strong> K-NN es un algoritmo de clasificación y regresión basado en la proximidad de los puntos de datos. Clasifica o predice un punto de datos basándose en la mayoría de los k vecinos más cercanos.<br></li>
                <li><strong>Características:</strong> Es un algoritmo simple y fácil de entender. Su rendimiento depende en gran medida de la elección del valor de k y de la métrica de distancia utilizada.<br></li>
                <li><strong>Fortalezas:</strong> Funciona bien cuando la relación entre las características y la etiqueta es compleja o no lineal. Es útil para tareas de clasificación y regresión.<br></li>
                <li><strong>Fundamentos:</strong> El K-NN determina la clase o valor de un punto de datos basándose en la clase o valores de sus vecinos más cercanos utilizando medidas de distancia como la distancia euclidiana.</li>
            </p>
        </section>

        <section>
            <h2>Redes Neuronales Artificiales (ANN):</h2>
            <p>
                <li><strong>Nombre:</strong> Redes Neuronales Artificiales (ANN).<br></li>
                <li><strong>Especificaciones:</strong> Las ANN son modelos computacionales inspirados en el cerebro humano que consisten en capas de nodos interconectados (neuronas artificiales).<br></li>
                <li><strong>Características:</strong> Pueden modelar relaciones extremadamente complejas y se utilizan en una amplia variedad de aplicaciones, incluyendo visión por computadora y procesamiento de lenguaje natural.<br></li>
                <li><strong>Fortalezas:</strong> Capacidad para aprender patrones sofisticados y realizar tareas de procesamiento de datos complejas. Son muy flexibles y escalables.<br></li>
                <li><strong>Fundamentos:</strong> Las ANN utilizan funciones de activación y algoritmos de retropropagación para ajustar los pesos de las conexiones entre nodos, lo que permite el aprendizaje de representaciones cada vez más abstractas.</li>
            </p>
        </section>

        <section>
            <h2>Bosques Aleatorios (Random Forests):</h2>
            <p>
                <li><strong>Nombre:</strong> Bosques Aleatorios (Random Forests).<br></li>
                <li><strong>Especificaciones:</strong> Los Bosques Aleatorios son conjuntos de árboles de decisión que se utilizan en problemas de clasificación y regresión.<br></li>
                <li><strong>Características:</strong> Combina múltiples árboles de decisión para reducir el sobreajuste y mejorar la generalización.<br></li>
                <li><strong>Fortalezas:</strong> Robustos y eficaces para conjuntos de datos grandes. Pueden manejar características numéricas y categóricas, y son resistentes al overfitting.<br></li>
                <li><strong>Fundamentos:</strong> Los Bosques Aleatorios utilizan el concepto de "ensamble" para combinar la predicción de varios árboles de decisión, lo que resulta en una predicción más sólida y precisa.</li>
            </p>
        </section>

        <section>
            <h2>Naive Bayes:</h2>
            <p>
                <li><strong>Nombre:</strong> Naive Bayes.<br>
                <li><strong>Especificaciones:</strong> El Naive Bayes es un algoritmo de clasificación basado en el teorema de Bayes. Es especialmente adecuado para el procesamiento de texto y la clasificación de documentos.<br></li>
                <li><strong>Características:</strong> Es simple y rápido. Se basa en el principio de independencia condicional entre las características.<br></li>
                <li><strong>Fortalezas:</strong> Eficaz en tareas de clasificación de texto, como el filtrado de spam y la categorización de documentos. Puede manejar conjuntos de datos con muchas características.<br></li>
                <li><strong>Fundamentos:</strong> Se basa en el teorema de Bayes para calcular la probabilidad condicional de una etiqueta dada las características observadas, asumiendo la independencia condicional entre las características.</li>
            </p>
        </section>
    </main>
</body>
</html>
